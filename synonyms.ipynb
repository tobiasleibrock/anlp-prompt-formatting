{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import aisuite as ai\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# client = ai.Client({\"groq\": {\"api_key\": os.getenv(\"GROQ_API_KEY\")}})\n",
    "# model = \"groq:llama-3.1-70b-versatile\"\n",
    "# model_name = \"llama-3_1-70b-versatile\"\n",
    "\n",
    "client = ai.Client({\"openai\": {\"api_key\": os.getenv(\"OPENAI_API_KEY\")}})\n",
    "model = \"openai:gpt-4o-mini\"\n",
    "model_name = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr, why did the pirate go to school? \n",
      "\n",
      "To improve his ‚Äúarrrrrrrrrticulation!‚Äù Har har har!\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Respond in Pirate English.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a joke.\"},\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(model=model, messages=messages, temperature=0.75)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formats from paper \"How I learned to start worrying about prompt formatting\"\n",
    "\n",
    "# Utility for Roman numeral conversion\n",
    "def to_roman(num):\n",
    "    roman_dict = {\n",
    "        1: \"I\", 2: \"II\", 3: \"III\", 4: \"IV\", 5: \"V\", 6: \"VI\", 7: \"VII\", 8: \"VIII\", 9: \"IX\", 10: \"X\"\n",
    "    }\n",
    "    return roman_dict.get(num, str(num))\n",
    "\n",
    "def to_lower_roman(num):\n",
    "    return to_roman(num).lower()\n",
    "\n",
    "# Format classes\n",
    "S1 = [\"\", \" \", \"\\n\", \" -- \", \"; \\n\", \" || \", \"< sep >\", \" - \", \"\\n \"]\n",
    "S2 = [\"\", \" \", \"  \", \"\\t\"]  # No space, single, double, tab\n",
    "C = [\"\", \" ::: \", \" :: \", \" : \", \"\\n\\t\", \"\\n \", \": \", \" - \", \"\\t\"]\n",
    "Fcasing = [lambda x: x, lambda x: x.title(), lambda x: x.upper(), lambda x: x.lower()]\n",
    "Fitem1 = [\n",
    "    lambda x: f\"({x})\",\n",
    "    lambda x: f\"{x}.\",\n",
    "    lambda x: f\"{x})\",\n",
    "    lambda x: f\"{x} )\",\n",
    "    lambda x: f\"[{x}]\",\n",
    "    lambda x: f\"<{x}>\"\n",
    "]\n",
    "Fitem2 = [\n",
    "    lambda x: x + 1,\n",
    "    lambda x: f\"A{x}\",\n",
    "    lambda x: f\"a{x}\",\n",
    "    lambda x: f\"{0x215F + x}\",\n",
    "    to_roman,\n",
    "    to_lower_roman\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the text into one of the options\n",
      "Only respond with the answer, no other text or explanation.\n",
      "Example: Example A\n",
      "Example: Example B\n",
      "Task: Choose the best answer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the PromptTemplate class to create prompt templates\n",
    "\n",
    "from prompt_template import PromptTemplate\n",
    "\n",
    "instruction = \"Classify the text into one of the options\"\n",
    "examples = [\"Example A\", \"Example B\"]\n",
    "task = \"Choose the best answer\"\n",
    "separator = \": \"\n",
    "word_separator = \" \"\n",
    "casing = Fcasing[0]             # as is\n",
    "field_separator = S1[2]         # \"\\n\"\n",
    "item_formatter = Fitem2[4]      # Roman numerals\n",
    "enumerator_format = Fitem1[0]   # Parentheses\n",
    "\n",
    "template = PromptTemplate(instruction, task, \" \", examples, separator, word_separator, casing, field_separator, item_formatter, enumerator_format)\n",
    "formatted_prompt = template.construct_prompt()\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From üëâv4.50üëà onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['air', 'view', 'sun', 'food']\n"
     ]
    }
   ],
   "source": [
    "# Example of synonym generation using the generate_synonyms function\n",
    "\n",
    "from synonyms_functions import generate_synonyms\n",
    "\n",
    "synonyms = generate_synonyms(text=\"the weather is nice today\", target_word=\"weather\", top_k=5)\n",
    "print(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7617836594581604\n"
     ]
    }
   ],
   "source": [
    "# Example of using the semantic_similarity function\n",
    "\n",
    "from synonyms_functions import semantic_similarity\n",
    "\n",
    "text1 = \"the weather is nice today\"\n",
    "text2 = \"the air is nice today\"\n",
    "\n",
    "similarity = semantic_similarity(text1, text2)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the text into one of the options\n",
      "Only respond with the answer, no other text or explanation.\n",
      "Example: Example A\n",
      "Example: Example B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "-----------------------------------------\n",
      "Example --> example\n",
      "\n",
      "Classify the question into one of the options\n",
      "Only respond with the answer, no other question or explanation.\n",
      "example: example A\n",
      "example: example B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8558414578437805 \n",
      "\n",
      "text --> question\n",
      "\n",
      "Classify the question into one of the options\n",
      "Only respond with the answer, no other question or explanation.\n",
      "example: example A\n",
      "example: example B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8558414578437805 \n",
      "\n",
      "-----------------------------------------\n",
      "Example --> example\n",
      "\n",
      "Classify the answer into one of the options\n",
      "Only respond with the answer, no other answer or explanation.\n",
      "example: example A\n",
      "example: example B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8922072649002075 \n",
      "\n",
      "text --> answer\n",
      "\n",
      "Classify the answer into one of the options\n",
      "Only respond with the answer, no other answer or explanation.\n",
      "example: example A\n",
      "example: example B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8922072649002075 \n",
      "\n",
      "-----------------------------------------\n",
      "Example --> example\n",
      "\n",
      "Classify the questions into one of the options\n",
      "Only respond with the answer, no other questions or explanation.\n",
      "example: example A\n",
      "example: example B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8253186345100403 \n",
      "\n",
      "text --> questions\n",
      "\n",
      "Classify the questions into one of the options\n",
      "Only respond with the answer, no other questions or explanation.\n",
      "example: example A\n",
      "example: example B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8253186345100403 \n",
      "\n",
      "-----------------------------------------\n",
      "Example --> examples\n",
      "\n",
      "Classify the question into one of the options\n",
      "Only respond with the answer, no other question or explanation.\n",
      "examples: examples A\n",
      "examples: examples B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8291038870811462 \n",
      "\n",
      "text --> question\n",
      "\n",
      "Classify the question into one of the options\n",
      "Only respond with the answer, no other question or explanation.\n",
      "examples: examples A\n",
      "examples: examples B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8291038870811462 \n",
      "\n",
      "-----------------------------------------\n",
      "Example --> examples\n",
      "\n",
      "Classify the answer into one of the options\n",
      "Only respond with the answer, no other answer or explanation.\n",
      "examples: examples A\n",
      "examples: examples B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8734899163246155 \n",
      "\n",
      "text --> answer\n",
      "\n",
      "Classify the answer into one of the options\n",
      "Only respond with the answer, no other answer or explanation.\n",
      "examples: examples A\n",
      "examples: examples B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8734899163246155 \n",
      "\n",
      "-----------------------------------------\n",
      "Example --> examples\n",
      "\n",
      "Classify the questions into one of the options\n",
      "Only respond with the answer, no other questions or explanation.\n",
      "examples: examples A\n",
      "examples: examples B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8048055171966553 \n",
      "\n",
      "text --> questions\n",
      "\n",
      "Classify the questions into one of the options\n",
      "Only respond with the answer, no other questions or explanation.\n",
      "examples: examples A\n",
      "examples: examples B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8048055171966553 \n",
      "\n",
      "-----------------------------------------\n",
      "Example --> instance\n",
      "\n",
      "Classify the question into one of the options\n",
      "Only respond with the answer, no other question or explanation.\n",
      "instance: instance A\n",
      "instance: instance B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.811745822429657 \n",
      "\n",
      "text --> question\n",
      "\n",
      "Classify the question into one of the options\n",
      "Only respond with the answer, no other question or explanation.\n",
      "instance: instance A\n",
      "instance: instance B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.811745822429657 \n",
      "\n",
      "-----------------------------------------\n",
      "Example --> instance\n",
      "\n",
      "Classify the answer into one of the options\n",
      "Only respond with the answer, no other answer or explanation.\n",
      "instance: instance A\n",
      "instance: instance B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8350890278816223 \n",
      "\n",
      "text --> answer\n",
      "\n",
      "Classify the answer into one of the options\n",
      "Only respond with the answer, no other answer or explanation.\n",
      "instance: instance A\n",
      "instance: instance B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8350890278816223 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example use of the rephrase function\n",
    "\n",
    "from synonyms_functions import rephrase\n",
    "\n",
    "modified_templates = rephrase(prompt=formatted_prompt, target_words=[\"Example\", \"text\"], top_k=3, similarity_threshold=0.8)\n",
    "\n",
    "print(modified_templates[0]['prompt'],\"\\n\")\n",
    "for i in range(0, len(modified_templates)):\n",
    "    print(\"-----------------------------------------\")\n",
    "    for j in range(0, len(modified_templates[i]['synonyms'])):\n",
    "        print(modified_templates[i]['target_words'][j],\"-->\",modified_templates[i]['synonyms'][j])\n",
    "        print()\n",
    "        print(modified_templates[i]['rephrased_prompt'],\"\\n\")\n",
    "        print(\"Semantic similarity:\", modified_templates[i]['similarity'],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: 7274\n",
      "a: 3456\n",
      "in: 2623\n",
      "to: 2430\n",
      "is: 2119\n",
      "you: 1987\n",
      "of: 1953\n",
      "given: 1906\n",
      "and: 1864\n",
      "are: 1363\n",
      "sentence: 1269\n",
      "or: 1146\n",
      "task: 1113\n",
      "answer: 1085\n",
      "be: 989\n",
      "question: 986\n",
      "that: 972\n",
      "this: 939\n",
      "your: 898\n",
      "not: 736\n",
      "with: 693\n",
      "an: 647\n",
      "should: 612\n",
      "language: 611\n",
      "if: 569\n",
      "from: 564\n",
      "it: 550\n",
      "as: 540\n",
      "for: 513\n",
      "on: 415\n",
      "by: 402\n",
      "one: 380\n",
      "text: 374\n",
      "will: 354\n",
      "correct: 345\n",
      "two: 337\n",
      "translation: 333\n",
      "into: 324\n",
      "need: 311\n",
      "must: 311\n",
      "can: 310\n",
      "which: 306\n",
      "have: 306\n",
      "english: 294\n",
      "translate: 292\n",
      "words: 279\n",
      "list: 271\n",
      "word: 269\n",
      "information: 262\n",
      "only: 258\n",
      "generate: 250\n",
      "e: 248\n",
      "based: 247\n",
      "input: 247\n",
      "output: 246\n",
      "passage: 239\n",
      "about: 237\n",
      "1: 234\n",
      "no: 223\n",
      "sentences: 223\n",
      "statement: 221\n",
      "b: 220\n",
      "2: 212\n",
      "same: 209\n",
      "we: 202\n",
      "context: 196\n",
      "job: 190\n",
      "classify: 190\n",
      "each: 187\n",
      "yes: 171\n",
      "original: 171\n",
      "questions: 170\n",
      "whether: 167\n",
      "do: 164\n",
      "i: 162\n",
      "story: 162\n",
      "s: 157\n",
      "answers: 157\n",
      "number: 157\n",
      "write: 152\n",
      "also: 149\n",
      "there: 148\n",
      "4: 146\n",
      "g: 143\n",
      "all: 140\n",
      "them: 140\n",
      "options: 140\n",
      "return: 139\n",
      "paragraph: 137\n",
      "please: 136\n",
      "review: 135\n",
      "c: 134\n",
      "event: 132\n",
      "has: 132\n",
      "add: 129\n",
      "option: 129\n",
      "most: 127\n",
      "between: 127\n",
      "numbers: 126\n",
      "following: 125\n"
     ]
    }
   ],
   "source": [
    "# Word frequency analysis on natural instructions dataset task definitions\n",
    "\n",
    "from word_frequency import read_json_files, count_word_frequencies\n",
    "\n",
    "directory = 'natural-instructions/tasks'\n",
    "texts = read_json_files(directory)\n",
    "word_frequencies = count_word_frequencies(texts)\n",
    "\n",
    "# Display the 100 most common words\n",
    "for word, freq in word_frequencies.most_common(100):\n",
    "    print(f'{word}: {freq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing task: task069_abductivenli_classification.json\n",
      "Saving progress after 10 instances...\n",
      "Saving progress after 20 instances...\n",
      "Saving progress after 30 instances...\n",
      "Saving progress after 40 instances...\n",
      "Saving progress after 50 instances...\n"
     ]
    }
   ],
   "source": [
    "from synonyms_functions import synonym_evaluation\n",
    "\n",
    "tasks = [\"task069_abductivenli_classification.json\",\"task065_timetravel_consistent_sentence_classification.json\"]\n",
    "target_words = [\"you\"]\n",
    "fname = f\"models/{model_name}_synonym_rules.json\"\n",
    "\n",
    "synonym_evaluation(client, model, fname, tasks, target_words, Fcasing, S1, Fitem2, Fitem1, top_k=5, save_every_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you example is to classify the text into one of their options\n"
     ]
    }
   ],
   "source": [
    "from synonyms_functions import apply_synonym_rules\n",
    "\n",
    "text1 = \"the example is to classify the text into one of the options\"\n",
    "synonym_rules_path = f\"models/{model_name}_synonym_rules.json\"\n",
    "\n",
    "text2 = apply_synonym_rules(text1, synonym_rules_path, similarity_threshold=0.95)\n",
    "print(text2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
