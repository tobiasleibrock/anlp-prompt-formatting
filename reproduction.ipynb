{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_dotenv' from 'dotenv' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01maisuite\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mai\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'load_dotenv' from 'dotenv' (unknown location)"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import aisuite as ai\n",
    "import os\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# client = ai.Client({\"groq\": {\"api_key\": os.getenv(\"GROQ_API_KEY\")}})\n",
    "# model = \"groq:llama-3.1-70b-versatile\"\n",
    "\n",
    "client = ai.Client({\"openai\": {\"api_key\": os.getenv(\"OPENAI_API_KEY\")}})\n",
    "model = \"openai:gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRespond in Pirate English.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m      3\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTell me a joke.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m      4\u001b[0m ]\n\u001b[1;32m----> 6\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(model\u001b[38;5;241m=\u001b[39mmodel, messages\u001b[38;5;241m=\u001b[39mmessages, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.75\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Respond in Pirate English.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a joke.\"},\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(model=model, messages=messages, temperature=0.75)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In this task, you will be shown a short story with a beginning, two potential middles, and an ending. Your job is to choose the middle statement that makes the story coherent / plausible by writing \"1\" or \"2\" in the output. If both sentences are plausible, pick the one that makes most sense.']\n",
      "agreement:  True output:  1 ground_truth:  1\n",
      "agreement:  True output:  1 ground_truth:  1\n",
      "agreement:  True output:  2 ground_truth:  2\n",
      "agreement:  True output:  1 ground_truth:  1\n",
      "agreement:  False output:  2 ground_truth:  1\n"
     ]
    }
   ],
   "source": [
    "# run task 069 for 5 runs\n",
    "\n",
    "task = \"natural-instructions/tasks/task069_abductivenli_classification.json\"\n",
    "runs = 5\n",
    "\n",
    "with open(task, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(data[\"Definition\"])\n",
    "\n",
    "for i in range(runs):\n",
    "    input = data[\"Instances\"][i][\"input\"]\n",
    "    output = data[\"Instances\"][i][\"output\"][0]\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": data[\"Definition\"][0]},\n",
    "        {\"role\": \"user\", \"content\": input},\n",
    "    ]\n",
    "    response = client.chat.completions.create(model=model, messages=messages, temperature=0.75)\n",
    "    print(\"agreement: \", output == response.choices[0].message.content, \"output: \", response.choices[0].message.content, \"ground_truth: \", output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "construct_prompt() takes 9 positional arguments but 10 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 84\u001b[0m\n\u001b[0;32m     81\u001b[0m item_formatter \u001b[38;5;241m=\u001b[39m Fitem2[\u001b[38;5;241m4\u001b[39m]  \u001b[38;5;66;03m# Roman numerals\u001b[39;00m\n\u001b[0;32m     82\u001b[0m enumerator_format \u001b[38;5;241m=\u001b[39m Fitem1[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Parentheses\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m formatted_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mconstruct_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstruction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseparator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield_separator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_formatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menumerator_format\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(formatted_prompt)\n",
      "\u001b[1;31mTypeError\u001b[0m: construct_prompt() takes 9 positional arguments but 10 were given"
     ]
    }
   ],
   "source": [
    "# formats from paper \"How I learned to start worrying about prompt formatting\"\n",
    "\n",
    "# Utility for Roman numeral conversion\n",
    "def to_roman(num):\n",
    "    roman_dict = {\n",
    "        1: \"I\", 2: \"II\", 3: \"III\", 4: \"IV\", 5: \"V\", 6: \"VI\", 7: \"VII\", 8: \"VIII\", 9: \"IX\", 10: \"X\"\n",
    "    }\n",
    "    return roman_dict.get(num, str(num))\n",
    "\n",
    "def to_lower_roman(num):\n",
    "    return to_roman(num).lower()\n",
    "\n",
    "# Format classes\n",
    "S1 = [\"\", \" \", \"\\n\", \" -- \", \"; \\n\", \" || \", \"< sep >\", \" - \", \"\\n \"]\n",
    "S2 = [\"\", \" \", \"  \", \"\\t\"]  # No space, single, double, tab\n",
    "C = [\"\", \" ::: \", \" :: \", \" : \", \"\\n\\t\", \"\\n \", \": \", \" - \", \"\\t\"]\n",
    "Fcasing = [lambda x: x, lambda x: x.title(), lambda x: x.upper(), lambda x: x.lower()]\n",
    "Fitem1 = [\n",
    "    lambda x: f\"({x})\",\n",
    "    lambda x: f\"{x}.\",\n",
    "    lambda x: f\"{x})\",\n",
    "    lambda x: f\"{x} )\",\n",
    "    lambda x: f\"[{x}]\",\n",
    "    lambda x: f\"<{x}>\"\n",
    "]\n",
    "Fitem2 = [\n",
    "    lambda x: x + 1,\n",
    "    lambda x: f\"A{x}\",\n",
    "    lambda x: f\"a{x}\",\n",
    "    lambda x: f\"{0x215F + x}\",\n",
    "    to_roman,\n",
    "    to_lower_roman\n",
    "]\n",
    "\n",
    "# Prompt formatting functions\n",
    "def format_field(descriptor, separator, casing, value):\n",
    "    \"\"\"\n",
    "    Formats a single field with a descriptor, separator, casing, and placeholder value.\n",
    "    \"\"\"\n",
    "    descriptor = casing(descriptor)\n",
    "    return f\"{descriptor}{separator}{value}\"\n",
    "\n",
    "def format_prompt(fields, field_separator, space):\n",
    "    \"\"\"\n",
    "    Combines multiple formatted fields with a given separator and spacing.\n",
    "    \"\"\"\n",
    "    return field_separator.join(fields).replace(\" \", space)\n",
    "\n",
    "def format_enumeration(descriptor, items, separator, space, casing, item_formatter):\n",
    "    \"\"\"\n",
    "    Formats enumerations (e.g., multiple-choice options) with specific formatting for items.\n",
    "    \"\"\"\n",
    "    formatted_items = [format_field(descriptor, separator, casing, item_formatter(i)) for i in items]\n",
    "    return format_prompt(formatted_items, field_separator=space, space=\" \")\n",
    "\n",
    "# Example main prompt constructor\n",
    "def construct_prompt(\n",
    "    instruction, examples, task, separator, space, casing, field_separator, item_formatter, enumerator_format\n",
    "):\n",
    "    \"\"\"\n",
    "    Constructs a complete prompt with instruction, examples, task, and formatting.\n",
    "    \"\"\"\n",
    "    instruction = casing(instruction)\n",
    "    formatted_examples = [\n",
    "        format_field(\"Example\", separator, casing, example) for example in examples\n",
    "    ]\n",
    "    formatted_task = format_field(\"Task\", separator, casing, task)\n",
    "    enumeration = format_enumeration(\n",
    "        \"Option\", range(1, 4), separator, space, casing, item_formatter\n",
    "    )\n",
    "    return format_prompt([instruction] + formatted_examples + [formatted_task, enumeration], field_separator, space)\n",
    "\n",
    "# Example usage\n",
    "instruction = \"Classify the text into one of the options\"\n",
    "examples = [\"Example A\", \"Example B\"]\n",
    "task = \"Choose the best answer\"\n",
    "separator = \": \"\n",
    "space = \"\\n\"\n",
    "casing = Fcasing[2]  # Uppercase\n",
    "field_separator = S1[3]  # \"--\"\n",
    "item_formatter = Fitem2[4]  # Roman numerals\n",
    "enumerator_format = Fitem1[0]  # Parentheses\n",
    "\n",
    "formatted_prompt = construct_prompt(\n",
    "    instruction, examples, task, separator, space, casing, field_separator, item_formatter, enumerator_format\n",
    ")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the text into one of the options\n",
      "Only respond with the answer, no other text or explanation.\n",
      "Example: Example A\n",
      "Example: Example B\n",
      "Task: Choose the best answer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the PromptTemplate class to create prompt templates\n",
    "\n",
    "from prompt_template import PromptTemplate\n",
    "\n",
    "instruction = \"Classify the text into one of the options\"\n",
    "examples = [\"Example A\", \"Example B\"]\n",
    "task = \"Choose the best answer\"\n",
    "separator = \": \"\n",
    "word_separator = \" \"\n",
    "casing = Fcasing[0]             # as is\n",
    "field_separator = S1[2]         # \"\\n\"\n",
    "item_formatter = Fitem2[4]      # Roman numerals\n",
    "enumerator_format = Fitem1[0]   # Parentheses\n",
    "\n",
    "template = PromptTemplate(instruction, task, \" \", examples, separator, word_separator, casing, field_separator, item_formatter, enumerator_format)\n",
    "formatted_prompt = template.construct_prompt()\n",
    "print(formatted_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different prompt mutations\n",
    "\n",
    "instruction = \"Classify the text into one of the options\"\n",
    "examples = [\"Example A\", \"Example B\"]\n",
    "task = \"Choose the best answer\"\n",
    "separator = \": \"\n",
    "space = \" \"\n",
    "\n",
    "for i in range(len(Fcasing)):\n",
    "    casing = Fcasing[i]\n",
    "    for j in range(len(S1)):\n",
    "        field_separator = S1[j]\n",
    "        for k in range(len(Fitem2)):\n",
    "            item_formatter = Fitem2[k]\n",
    "            for l in range(len(Fitem1)):\n",
    "                enumerator_format = Fitem1[l]\n",
    "                template = PromptTemplate(instruction,\n",
    "                                    task,\n",
    "                                    examples,\n",
    "                                    separator,\n",
    "                                    word_separator,\n",
    "                                    casing,\n",
    "                                    field_separator,\n",
    "                                    item_formatter,\n",
    "                                    enumerator_format)\n",
    "                formatted_prompt = template.construct_prompt()\n",
    "                #print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02.12.2024\n",
    "# - q&a dataset extend with prompts\n",
    "# - orca dataset (https://huggingface.co/microsoft/Orca-2-13b)\n",
    "# - shap value and lime -> phrase mutations as binary vector\n",
    "# - estimate influence of each mutation on the result\n",
    "# - look into implementations of this -> free on github maybe easy to use out of the box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weather', 'air', 'view', 'sun', 'food']\n"
     ]
    }
   ],
   "source": [
    "from generate_synonyms import generate_synonyms\n",
    "\n",
    "synonyms = generate_synonyms(text=\"the weather is nice today\", target_word=\"weather\", top_k=5)\n",
    "print(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the text into one of the options\n",
      "Only respond with the answer, no other text or explanation.\n",
      "Example: Example A\n",
      "Example: Example B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "-----------------------------------------\n",
      "Example --> example\n",
      "text --> question\n",
      "\n",
      "Classify the question into one of the options\n",
      "Only respond with the answer, no other question or explanation.\n",
      "example: example A\n",
      "example: example B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8558414578437805 \n",
      "\n",
      "-----------------------------------------\n",
      "Example --> example\n",
      "text --> answer\n",
      "\n",
      "Classify the answer into one of the options\n",
      "Only respond with the answer, no other answer or explanation.\n",
      "example: example A\n",
      "example: example B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8922072649002075 \n",
      "\n",
      "-----------------------------------------\n",
      "Example --> example\n",
      "text --> questions\n",
      "\n",
      "Classify the questions into one of the options\n",
      "Only respond with the answer, no other questions or explanation.\n",
      "example: example A\n",
      "example: example B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8253186345100403 \n",
      "\n",
      "-----------------------------------------\n",
      "Example --> examples\n",
      "text --> question\n",
      "\n",
      "Classify the question into one of the options\n",
      "Only respond with the answer, no other question or explanation.\n",
      "examples: examples A\n",
      "examples: examples B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8291038870811462 \n",
      "\n",
      "-----------------------------------------\n",
      "Example --> examples\n",
      "text --> answer\n",
      "\n",
      "Classify the answer into one of the options\n",
      "Only respond with the answer, no other answer or explanation.\n",
      "examples: examples A\n",
      "examples: examples B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8734899163246155 \n",
      "\n",
      "-----------------------------------------\n",
      "Example --> examples\n",
      "text --> questions\n",
      "\n",
      "Classify the questions into one of the options\n",
      "Only respond with the answer, no other questions or explanation.\n",
      "examples: examples A\n",
      "examples: examples B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8048055171966553 \n",
      "\n",
      "-----------------------------------------\n",
      "Example --> instance\n",
      "text --> question\n",
      "\n",
      "Classify the question into one of the options\n",
      "Only respond with the answer, no other question or explanation.\n",
      "instance: instance A\n",
      "instance: instance B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.811745822429657 \n",
      "\n",
      "-----------------------------------------\n",
      "Example --> instance\n",
      "text --> answer\n",
      "\n",
      "Classify the answer into one of the options\n",
      "Only respond with the answer, no other answer or explanation.\n",
      "instance: instance A\n",
      "instance: instance B\n",
      "Task: Choose the best answer\n",
      " \n",
      "\n",
      "Semantic similarity: 0.8350890278816223 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from generate_synonyms import rephrase\n",
    "\n",
    "modified_templates = rephrase(prompt=formatted_prompt, target_words=[\"Example\", \"text\"], top_k=3, similarity_threshold=0.8)\n",
    "\n",
    "print(modified_templates[0]['prompt'],\"\\n\")\n",
    "for i in range(0, len(modified_templates)):\n",
    "    print(\"-----------------------------------------\")\n",
    "    for j in range(0, len(modified_templates[i]['synonyms'])):\n",
    "        print(modified_templates[i]['target_words'][j],\"-->\",modified_templates[i]['synonyms'][j])\n",
    "    print()\n",
    "    print(modified_templates[i]['rephrased_prompt'],\"\\n\")\n",
    "    print(\"Semantic similarity:\", modified_templates[i]['similarity'],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7617836594581604\n"
     ]
    }
   ],
   "source": [
    "from generate_synonyms import semantic_similarity\n",
    "\n",
    "text1 = \"the weather is nice today\"\n",
    "text2 = \"the air is nice today\"\n",
    "\n",
    "similarity = semantic_similarity(text1, text2)\n",
    "print(similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
