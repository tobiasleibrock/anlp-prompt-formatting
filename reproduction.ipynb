{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import aisuite as ai\n",
    "import os\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# client = ai.Client({\"groq\": {\"api_key\": os.getenv(\"GROQ_API_KEY\")}})\n",
    "# model = \"groq:llama-3.1-70b-versatile\"\n",
    "\n",
    "client = ai.Client({\"openai\": {\"api_key\": os.getenv(\"OPENAI_API_KEY\")}})\n",
    "model = \"openai:gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the pirate go to school? \n",
      "\n",
      "To improve his \"arrrrrrrticulation!\" Ha-ha!\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Respond in Pirate English.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a joke.\"},\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(model=model, messages=messages, temperature=0.75)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In this task, you will be shown a short story with a beginning, two potential middles, and an ending. Your job is to choose the middle statement that makes the story coherent / plausible by writing \"1\" or \"2\" in the output. If both sentences are plausible, pick the one that makes most sense.']\n",
      "agreement:  True output:  1 ground_truth:  1\n",
      "agreement:  True output:  1 ground_truth:  1\n",
      "agreement:  True output:  2 ground_truth:  2\n",
      "agreement:  True output:  1 ground_truth:  1\n",
      "agreement:  False output:  2 ground_truth:  1\n"
     ]
    }
   ],
   "source": [
    "# run task 069 for 5 runs\n",
    "\n",
    "task = \"natural-instructions/tasks/task069_abductivenli_classification.json\"\n",
    "runs = 5\n",
    "\n",
    "with open(task, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(data[\"Definition\"])\n",
    "\n",
    "for i in range(runs):\n",
    "    input = data[\"Instances\"][i][\"input\"]\n",
    "    output = data[\"Instances\"][i][\"output\"][0]\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": data[\"Definition\"][0]},\n",
    "        {\"role\": \"user\", \"content\": input},\n",
    "    ]\n",
    "    response = client.chat.completions.create(model=model, messages=messages, temperature=0.75)\n",
    "    print(\"agreement: \", output == response.choices[0].message.content, \"output: \", response.choices[0].message.content, \"ground_truth: \", output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFY\n",
      "THE\n",
      "TEXT\n",
      "INTO\n",
      "ONE\n",
      "OF\n",
      "THE\n",
      "OPTIONS\n",
      "--\n",
      "EXAMPLE:\n",
      "Example\n",
      "A\n",
      "--\n",
      "EXAMPLE:\n",
      "Example\n",
      "B\n",
      "--\n",
      "TASK:\n",
      "Choose\n",
      "the\n",
      "best\n",
      "answer\n",
      "--\n",
      "OPTION:\n",
      "I\n",
      "OPTION:\n",
      "II\n",
      "OPTION:\n",
      "III\n"
     ]
    }
   ],
   "source": [
    "# formats from paper \"How I learned to start worrying about prompt formatting\"\n",
    "\n",
    "# Utility for Roman numeral conversion\n",
    "def to_roman(num):\n",
    "    roman_dict = {\n",
    "        1: \"I\", 2: \"II\", 3: \"III\", 4: \"IV\", 5: \"V\", 6: \"VI\", 7: \"VII\", 8: \"VIII\", 9: \"IX\", 10: \"X\"\n",
    "    }\n",
    "    return roman_dict.get(num, str(num))\n",
    "\n",
    "def to_lower_roman(num):\n",
    "    return to_roman(num).lower()\n",
    "\n",
    "# Format classes\n",
    "S1 = [\"\", \" \", \"\\n\", \" -- \", \"; \\n\", \" || \", \"< sep >\", \" - \", \"\\n \"]\n",
    "S2 = [\"\", \" \", \"  \", \"\\t\"]  # No space, single, double, tab\n",
    "C = [\"\", \" ::: \", \" :: \", \" : \", \"\\n\\t\", \"\\n \", \": \", \" - \", \"\\t\"]\n",
    "Fcasing = [lambda x: x, lambda x: x.title(), lambda x: x.upper(), lambda x: x.lower()]\n",
    "Fitem1 = [\n",
    "    lambda x: f\"({x})\",\n",
    "    lambda x: f\"{x}.\",\n",
    "    lambda x: f\"{x})\",\n",
    "    lambda x: f\"{x} )\",\n",
    "    lambda x: f\"[{x}]\",\n",
    "    lambda x: f\"<{x}>\"\n",
    "]\n",
    "Fitem2 = [\n",
    "    lambda x: x + 1,\n",
    "    lambda x: f\"A{x}\",\n",
    "    lambda x: f\"a{x}\",\n",
    "    lambda x: f\"{0x215F + x}\",\n",
    "    to_roman,\n",
    "    to_lower_roman\n",
    "]\n",
    "\n",
    "# Prompt formatting functions\n",
    "def format_field(descriptor, separator, casing, value):\n",
    "    \"\"\"\n",
    "    Formats a single field with a descriptor, separator, casing, and placeholder value.\n",
    "    \"\"\"\n",
    "    descriptor = casing(descriptor)\n",
    "    return f\"{descriptor}{separator}{value}\"\n",
    "\n",
    "def format_prompt(fields, field_separator, space):\n",
    "    \"\"\"\n",
    "    Combines multiple formatted fields with a given separator and spacing.\n",
    "    \"\"\"\n",
    "    return field_separator.join(fields).replace(\" \", space)\n",
    "\n",
    "def format_enumeration(descriptor, items, separator, space, casing, item_formatter):\n",
    "    \"\"\"\n",
    "    Formats enumerations (e.g., multiple-choice options) with specific formatting for items.\n",
    "    \"\"\"\n",
    "    formatted_items = [format_field(descriptor, separator, casing, item_formatter(i)) for i in items]\n",
    "    return format_prompt(formatted_items, field_separator=space, space=\" \")\n",
    "\n",
    "# Example main prompt constructor\n",
    "def construct_prompt(\n",
    "    instruction, examples, task, separator, space, casing, field_separator, item_formatter, enumerator_format\n",
    "):\n",
    "    \"\"\"\n",
    "    Constructs a complete prompt with instruction, examples, task, and formatting.\n",
    "    \"\"\"\n",
    "    instruction = casing(instruction)\n",
    "    formatted_examples = [\n",
    "        format_field(\"Example\", separator, casing, example) for example in examples\n",
    "    ]\n",
    "    formatted_task = format_field(\"Task\", separator, casing, task)\n",
    "    enumeration = format_enumeration(\n",
    "        \"Option\", range(1, 4), separator, space, casing, item_formatter\n",
    "    )\n",
    "    return format_prompt([instruction] + formatted_examples + [formatted_task, enumeration], field_separator, space)\n",
    "\n",
    "# Example usage\n",
    "instruction = \"Classify the text into one of the options\"\n",
    "examples = [\"Example A\", \"Example B\"]\n",
    "task = \"Choose the best answer\"\n",
    "separator = \": \"\n",
    "space = \"\\n\"\n",
    "casing = Fcasing[2]  # Uppercase\n",
    "field_separator = S1[3]  # \"--\"\n",
    "item_formatter = Fitem2[4]  # Roman numerals\n",
    "enumerator_format = Fitem1[0]  # Parentheses\n",
    "\n",
    "formatted_prompt = construct_prompt(\n",
    "    instruction, examples, task, separator, space, casing, field_separator, item_formatter, enumerator_format\n",
    ")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the text into one of the options\n",
      "Only respond with the answer, no other text or explanation.\n",
      "Example: Example A\n",
      "Example: Example B\n",
      "Task: Choose the best answer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the PromptTemplate class to create prompt templates\n",
    "\n",
    "from prompt_template import PromptTemplate\n",
    "\n",
    "instruction = \"Classify the text into one of the options\"\n",
    "examples = [\"Example A\", \"Example B\"]\n",
    "task = \"Choose the best answer\"\n",
    "separator = \": \"\n",
    "word_separator = \" \"\n",
    "casing = Fcasing[0]             # as is\n",
    "field_separator = S1[2]         # \"\\n\"\n",
    "item_formatter = Fitem2[4]      # Roman numerals\n",
    "enumerator_format = Fitem1[0]   # Parentheses\n",
    "\n",
    "template = PromptTemplate(instruction, task, \" \", examples, separator, word_separator, casing, field_separator, item_formatter, enumerator_format)\n",
    "formatted_prompt = template.construct_prompt()\n",
    "print(formatted_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different prompt mutations\n",
    "\n",
    "instruction = \"Classify the text into one of the options\"\n",
    "examples = [\"Example A\", \"Example B\"]\n",
    "task = \"Choose the best answer\"\n",
    "separator = \": \"\n",
    "space = \" \"\n",
    "\n",
    "for i in range(len(Fcasing)):\n",
    "    casing = Fcasing[i]\n",
    "    for j in range(len(S1)):\n",
    "        field_separator = S1[j]\n",
    "        for k in range(len(Fitem2)):\n",
    "            item_formatter = Fitem2[k]\n",
    "            for l in range(len(Fitem1)):\n",
    "                enumerator_format = Fitem1[l]\n",
    "                template = PromptTemplate(instruction,\n",
    "                                    task,\n",
    "                                    examples,\n",
    "                                    separator,\n",
    "                                    word_separator,\n",
    "                                    casing,\n",
    "                                    field_separator,\n",
    "                                    item_formatter,\n",
    "                                    enumerator_format)\n",
    "                formatted_prompt = template.construct_prompt()\n",
    "                #print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02.12.2024\n",
    "# - q&a dataset extend with prompts\n",
    "# - orca dataset (https://huggingface.co/microsoft/Orca-2-13b)\n",
    "# - shap value and lime -> phrase mutations as binary vector\n",
    "# - estimate influence of each mutation on the result\n",
    "# - look into implementations of this -> free on github maybe easy to use out of the box"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
